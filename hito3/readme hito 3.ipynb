{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a265af85-c591-483b-b07f-89932e3b6764",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n de Anfibios mediante Deep Learning \n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un modelo de aprendizaje profundo (Deep Learning) capaz de identificar especies de anfibios a partir de grabaciones de audio. El proceso abarca desde el preprocesamiento de se√±ales de audio hasta el entrenamiento y evaluaci√≥n de una Red Neuronal Convolucional (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6af2d9-ce10-450c-86aa-0f1909cb327a",
   "metadata": {},
   "source": [
    "## üìã Tabla de Contenidos\n",
    "1. [Descripci√≥n del Proyecto](#descripci√≥n-del-proyecto)\n",
    "2. [Estructura del Repositorio](#estructura-del-repositorio)\n",
    "3. [Requisitos e Instalaci√≥n](#requisitos-e-instalaci√≥n)\n",
    "4. [Hito 2: Procesamiento de Datos](#hito-2-procesamiento-de-datos)\n",
    "5. [Hito 3: Entrenamiento del Modelo](#hito-3-entrenamiento-del-modelo)\n",
    "6. [Resultados](#resultados)\n",
    "7. [Autores](#autores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93d6fb-a323-47ea-ae2f-186832fb7d0d",
   "metadata": {},
   "source": [
    "## Estructura del Repositorio\n",
    "\n",
    "```bash\n",
    ".\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Audios originales en formato .wav\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ processed/           # Espectrogramas procesados (.npz) y metadata.csv\n",
    "‚îú‚îÄ‚îÄ notebooks/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Hito_2_Procesamiento.ipynb   # Notebook del Hito 2\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Hito_3_Entrenamiento.ipynb   # Notebook del Hito 3\n",
    "‚îú‚îÄ‚îÄ README.md                # Este archivo\n",
    "‚îî‚îÄ‚îÄ requirements.txt         # Librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483261e-a2f2-4222-9749-a3fc6d2b7372",
   "metadata": {},
   "source": [
    "### Celda 4 (Markdown): Requisitos e Instalaci√≥n\n",
    "\n",
    "\n",
    "Para ejecutar este proyecto, necesitas Python 3.8 o superior. Las principales librer√≠as utilizadas son:\n",
    "\n",
    "* `numpy`\n",
    "* `pandas`\n",
    "* `librosa` (para procesamiento de audio)\n",
    "* `matplotlib` / `seaborn` (para visualizaci√≥n)\n",
    "* `tensorflow` (para el modelo de Deep Learning)\n",
    "* `scikit-learn` (para m√©tricas y preprocesamiento)\n",
    "\n",
    "**Instalaci√≥n r√°pida:**\n",
    "```bash\n",
    "pip install numpy pandas librosa matplotlib seaborn tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e3e09-6461-4d2d-88ee-a02476fdb728",
   "metadata": {},
   "source": [
    "### Celda 5 (Markdown): Hito 2 - Procesamiento\n",
    "\n",
    "\n",
    "En esta etapa, nos enfocamos en transformar los audios crudos en una representaci√≥n visual √∫til para el modelo.\n",
    "\n",
    "**Actividades realizadas:**\n",
    "1.  **Carga de Audios:** Lectura de archivos `.wav` usando `librosa`.\n",
    "2.  **Extracci√≥n de Caracter√≠sticas:** Conversi√≥n de audio a **Espectrogramas de Mel** (representaci√≥n tiempo-frecuencia logar√≠tmica). \n",
    "3.  **Almacenamiento:** Los espectrogramas se guardaron como archivos comprimidos `.npz` para una carga eficiente.\n",
    "4.  **Metadata:** Se gener√≥ un archivo `metadata.csv` que vincula cada archivo procesado con su etiqueta (especie).\n",
    "5.  **Validaci√≥n:** Se visualiz√≥ una muestra de los espectrogramas para asegurar que la conversi√≥n fue correcta y se analiz√≥ el balance de clases.\n",
    "\n",
    "**Script principal:** `Procesamiento de Se√±al y Extracci√≥n de Caracter√≠sticas.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f75f0c-0606-4822-af3c-9dc6bca0a631",
   "metadata": {},
   "source": [
    "## Hito 3: Entrenamiento del Modelo üß†\n",
    "\n",
    "En esta fase, dise√±amos y entrenamos una Red Neuronal Convolucional (CNN) utilizando los datos procesados. \n",
    "\n",
    "**Actividades realizadas:**\n",
    "1.  **Preparaci√≥n del Dataset:**\n",
    "    * Carga de espectrogramas desde archivos `.npz`.\n",
    "    * Codificaci√≥n de etiquetas (`LabelEncoder` y `to_categorical`).\n",
    "    * Normalizaci√≥n de los datos (Z-score).\n",
    "    * Divisi√≥n en conjuntos de entrenamiento (Train) y prueba (Test).\n",
    "2.  **Arquitectura CNN:**\n",
    "    * Capas Convolucionales (`Conv2D`) para extracci√≥n de caracter√≠sticas.\n",
    "    * Capas de Pooling (`MaxPooling2D`) para reducci√≥n de dimensionalidad.\n",
    "    * Capas de Regularizaci√≥n (`Dropout`, `BatchNormalization`) para evitar sobreajuste.\n",
    "    * Capa de Salida (`Softmax`) para clasificaci√≥n multiclase.\n",
    "3.  **Entrenamiento Personalizado:**\n",
    "    * Se implement√≥ un **Callback personalizado** (`LambdaCallback`) para visualizar el progreso del entrenamiento (p√©rdida y precisi√≥n) con etiquetas en espa√±ol, mejorando la legibilidad de los logs.\n",
    "    * Optimizador: Adam.\n",
    "    * Funci√≥n de p√©rdida: Categorical Crossentropy.\n",
    "\n",
    "**Script principal:** `Hito 3 - Entrenamiento del Modelo.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5c7bf-079b-4b4a-966f-c80ce0a24a25",
   "metadata": {},
   "source": [
    "## Resultados üìä\n",
    "\n",
    "El modelo fue evaluado utilizando el conjunto de prueba (datos que la red nunca vio durante el entrenamiento).\n",
    "\n",
    "* **Exactitud Global (Accuracy):** [COMPLETAR CON TU % FINAL, ej: 85%]\n",
    "* **Matriz de Confusi√≥n:** Muestra qu√© especies se confunden entre s√≠.\n",
    "    * *(Ver gr√°fico generado en el notebook)*\n",
    "\n",
    "**Conclusiones preliminares:**\n",
    "El modelo logra distinguir eficazmente entre las especies, demostrando que el uso de espectrogramas de Mel es una estrategia efectiva para este problema de clasificaci√≥n de audio. La implementaci√≥n de callbacks personalizados permiti√≥ un seguimiento m√°s claro del proceso de aprendizaje.\n",
    "\n",
    "---\n",
    "\n",
    "## Autores ‚úíÔ∏è\n",
    "\n",
    "* **[Matias Mu√±oz]** - *Desarrollo y Entrenamiento*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf545ef2-3b70-449d-8d0f-60a2289d4848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acus_python",
   "language": "python",
   "name": "acus_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
